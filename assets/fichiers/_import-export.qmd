---
title: Import, export et plus encore...
Author: Samuel Guay
date: 11-08-2022
editor_options: 
  chunk_output_type: inline
df-print: kable
---

## [Tibble](https://tibble.tidyverse.org/articles/tibble.html)

Les tibbles nous facilite la vie lorsque nous travaillons avec des dataframes.
Ils ont √©t√© pens√©s afin d'enlever le maximum de friction lorsque nous devons
travailler avec des donn√©es tabulaires. Pour voir les diff√©rences avec les
dataframes, r√©f√©rez-vous √† la [documentation
officielle](https://tibble.tidyverse.org/articles/tibble.html).

Il est plut√¥t rare que nous travaillons explicitement avec les fonctions du
package `tibble`. Lorsque nous d√©veloppons du code dans le tidyverse, il s'agit
plut√¥t d'une utilisation implicite puisque tous les packages renvoient des
tibbles. Par contre, si nous devons transformer un vecteur ou un dataframe, les
principales fonctions que nous utilisons sont:

-   `as_tibble()` pour convertir un objet (data.frame) en tibble. C'est
    exactement le m√™me principe que lorsque nous utilisons `as.character()`,
    `as.numeric()`, etc.

    ```{r}
    library(tibble)
    dat <- data.frame(French = "Bonjour", English = "Hello", Score = 100)
    (dat <- as_tibble(dat))
    ```

-   `tibble()` pour cr√©er un tibble √† partir de rien:

    ```{r}
    tibble(x = 1:5, y = x ^ 2)
    ```

-   `tribble()` est pratique pour construire visuellement un tibble.

    ```{r}
    tribble(
      ~colA, ~colB,
      "a",   1,
      "b",   2,
      "c",   3
    )
    ```

::: callout-tip
La plupart des fonctions du Tidyverse remplacent le `.` par des `_` dans le nom
des fonctions.

Par exemple `read.csv()` vs `read_csv()`, etc. Anciennement, `as_tibble()`
s'appelait `as_data_frame()`.

On utilise couramment le terme dataframe m√™me si on r√©f√®re √† un tibble.
:::

Bref, lorsqu'on travaille avec des tibbles, nous sommes pratiquement toujours
en confiance que nous travaillerons toujours avec des tibbles lors de
proc√©dures de *subsetting* ou autre!

## Importation des donn√©es

Pour importer des donn√©es tabulaires aux formats classiques (`.CSV`, `.TSV`,
etc.), la proc√©dure est toujours relativement standard et similaire avec le
package d'importation de donn√©es officiel du Tidyverse
[readr](https://readr.tidyverse.org).

```{r}
library(readr)
```

Pour les donn√©es qui proviennent d'Excel, un package sp√©cialement fait pour ce
programme a √©t√© d√©velopp√© - [readxl](https://readxl.tidyverse.org/).

Pour les donn√©es qui proviennent de SPSS, Stata et SAS,
[haven](https://haven.tidyverse.org) est le package qu'il vous fait.

```{r, eval=FALSE}
# Importation d'un data set "parfait"
readcsv <- read_csv("https://open.canada.ca/data/dataset/4ed351cf-95d8-4c10-97ac-6b3511f359b7/resource/d0df95a8-31a9-46c9-853b-6952819ec7b4/download/inventory.csv")
```

Sans pr√©cision, `readr` (et compagnie) s'en sortent souvent tr√®s bien. Par
contre, il est possible de faire beaucoup plus.

::: callout-tip
## √Ä vous de jouer

Que signifie les options utilis√©es ci-dessous?

```{r, eval=FALSE}
readcsv <- read_csv("https://open.canada.ca/data/dataset/4ed351cf-95d8-4c10-97ac-6b3511f359b7/resource/d0df95a8-31a9-46c9-853b-6952819ec7b4/download/inventory.csv",
                    n_max = 50,
                    col_select = contains("fr"),
                    show_col_types = FALSE,
                    skip_empty_rows = TRUE
                    )
```
:::

Pour lire plusieurs fichiers identiques en m√™me temps:

Vous pouvez t√©l√©charger les fichiers suivants:

| CSV                                       | TSV                                       |
|----------------------------------------|----------------------------------------|
| [data_1.csv](/assets/fichiers/data_1.csv) | [data_1.tsv](/assets/fichiers/data_1.tsv) |
| [data_2.csv](/assets/fichiers/data_2.csv) | [data_2.tsv](/assets/fichiers/data_2.tsv) |
| [data_3.csv](/assets/fichiers/data_3.csv) | [data_3.tsv](/assets/fichiers/data_3.tsv) |
| [data_4.csv](/assets/fichiers/data_4.csv) | [data_4.tsv](/assets/fichiers/data_4.tsv) |

```{r}
(list.files(pattern = "*.csv"))
# fonction √©quivalente, mais plus portable avec le package fs
(csv_files <- fs::dir_ls(glob = "*.csv"))

read_csv(csv_files)

read_tsv(file = "data_2.tsv")
```

### Nettoyage

Un √©l√©ment important que nous pouvons faire lorsque nous importons les donn√©es
et un premier nettoyage. L'argument `name-repair` est ultra pertinent!

::: callout-note
## √Ä vous de jouer

Comment pourrions-nous nettoyer les noms de variable du dataset
[data_weird.tsv](/assets/fichiers/data_weird.tsv) seulement lors de
l'importation?
:::

```{r}
read_tsv("data_weird.tsv", 
         name_repair = )
```

ps: Connaissez-vous le package [janitor](https://sfirke.github.io/janitor/)?

## R√©colter des donn√©es directement sur Internet

Le site qui servira d'exemple est [Hacker News](https://news.ycombinator.com/),
surnomm√© [HN](https://news.ycombinator.com/) par la communaut√©.
[HN](https://news.ycombinator.com/) est maintenu par Y Combinator (YC),
probablement l'incubateur de startups le plus r√©put√© au monde. Les succ√®s
monstres de [plusieurs centaines](https://www.ycombinator.com/companies) de
compagnies, notamment AirBnB, DropBox, Stripe, Twitch et Reddit, ont
certainement contribu√© √† la notori√©t√© de YC.

[HN](https://news.ycombinator.com/) est un aggr√©gateur de nouvelles et de
discussions qui couvre tous les sujets susceptible de satisfaire la curiosit√©
intellectuelle de son lectorat. Les membres sont libres de soumettre leurs
projets (*Show HN)*, des nouvelles, des questions (*Ask HN)*, de vieux
articles, etc. De plus, la mod√©ration est tr√®s juste, ce qui emp√™che les
commentaires n√©gatifs gratuits tout en encourageant la critique.

Ce qui fait de HN un aggr√©gateur int√©ressant sont les soumissions qui sont
soumises aux lois d'un algorithme relativement simple. Dans leurs mots:

> ***How are stories ranked?** The basic algorithm divides points by a power of
> the time since a story was submitted. Comments in threads are ranked the same
> way. Other factors affecting rank include user flags, anti-abuse software,
> software which demotes overheated discussions, account or site weighting, and
> moderator action.*

Cela fait donc en sorte que ce soit un site int√©ressant √† investiguer et
r√©colter les donn√©es puisqu'elles changent toujours! Comme les nouvelles
changent de position et de pointage presque toujours, chaque fois que nous
r√©coltons des donn√©es de la premi√®re page, de nouvelles analyses sont
possibles.

Lorsque nous r√©coltons des donn√©es √† partir d'un site web directement, il est
important de v√©rifier le fichier `robots.txt` afin de s'assurer que nous avons
le droit de proc√©der ainsi. Un fichier robots.txt est un ensemble
d'instructions pour les robots principalement. Par exemple, dans le cas de HN,
[https://news.ycombinator.com/robots.txt](https://news.ycombinator.com/robots.txthttps://news.ycombinator.com/robots.txt),
il est possible de le faire sur les pages principales, mais pas celles qui
contiennent `/threads?` dans leur URL par exemple.

    User-Agent: *
    Disallow: /x?
    Disallow: /r?
    Disallow: /vote?
    Disallow: /reply?
    Disallow: /submitted?
    Disallow: /submitlink?
    Disallow: /threads?
    Crawl-delay: 30

Ceci √©tant dit, proc√©dons √† notre premi√®re r√©colte qui se fera principalement
avec [rvest](https://rvest.tidyverse.org), le package d√©di√© √† cette t√¢che dans
le `Tidyverse`!

```{r}
# Importer le package n√©cessaire
library(rvest)

```

### Sp√©cifier le lien et lire la page

```{r}
url <- "https://news.ycombinator.com/"

raw_html <- read_html(x = url)

raw_html
```

Tout ce qu'on vient de faire est de lire litt√©ralementle contenu de la page que
nous voyons √† `r url` de fa√ßon int√©grale. √âvidemment, nous la voyons avec plus
de style dans un fureteur, mais il s'agit contenu m√™me contenu!

Cependant, ce que nous voyons dans un fureteur est contenu seulement dans la
partie `<body>...</body>` du code que nous voyons. `<body>` repr√©sente un tag
html. Les tags sont les √©l√©ments le plus importants √† retenir ici, car tout se
fera √† partir des tags html.

::: callout-tip
Lorsque nous ne parviendrons pas √† obtenir ce que nous voulons avec les tags,
nous devrons nous rabattre sur les s√©lecteurs de CSS, souvent les classes. Il
est possible d'utiliser des aides comme
[SelectorGadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb),
mais nous verrons que nous pouvons utiliser directement notre fureteur pour
arriver √† nos fins!

Enfin, lorsque les s√©lecteurs CSS ne fonctionnent pas, il est possible de
s√©lectionner ce que nous voulons vraiment par diff√©rents moyens dont les
expressions XPath et/ou les expressions r√©guli√®res. Cela demande souvent
beaucoup d'essais et d'erreurs avant d'y parvenir.
:::

Ceci √©tant dit, nous pouvons donc s√©lectionner seulement le `<body>` comme le
contenu qui nous int√©resse s'y trouve. Les fonctions `html_element()` ou
`html_elements()` seront souvent les premi√®res √† √™tre utiliser afin de
sp√©cifier ce que nous voulons, selon si nous voulons un seul √©l√©ment ou
plusieurs √©l√©ments identiques.

```{r}
raw_body <- html_element(x = raw_html,
                         css = "body")

raw_body
```

Maintenant que nous avons seulement le contenu, nous pouvons extraire le texte
avec `html_text()` afin de v√©rifier si, par magie, nous avons un beau tableau
avec des donn√©es.

```{r}
html_text(x = raw_body, trim = TRUE)
```

Oh mis√®re, tout le texte vient en un seul morceau, il faut donc raffiner notre
s√©lection en investiguant le code dans le fureteur afin d'extraire seulement ce
que nous voulons avec les attributs comme nous avons fait pour `<body>`!

Bien que `<table>` semble l'option facile, nous constatons vite qu'il a
plusieurs tables, 4 au total dispers√©es dans toute la page, parfois une
imbriqu√©es dans l'autre. Nous aimons les `<table>`, car il y a une fonction
`html_table()` d√©di√©e puisque c'est tr√®s commun. Lorsqu'on scrute le code HTML,
une table en particulier contient la classe CSS `.itemlist` et celle-ci semble
unique aux items. On pourrait √©galement √™tre encore plus pr√©cis en ajoutant
`table.itemlist`, mais dans ce cas, cela revient au m√™me.

Ce qu'on remarque ici, c'est que la table n'est par parfaite pour extraire
directement tous les √©l√©ments facilement.

html_table()

```{r}
items <- html_element(x = raw_body,
                         css = ".itemlist")
items
```

On semble avoir une table qui m√©rite l'utilisation de `html_table()`. Par
contre, on remarquera rapidement qu'il y a quelque chose qui cloche.

```{r}
dim(html_table(x = items))
html_table(x = items)

```

Alors qu'il n'y a que 30 items sur la page web, ici nous obtenons un tibble de
`r nrow(html_table(x = items))` rang√©es et `r ncol(html_table(x = items))`
colonnes. La troisi√®me colonne semble √™tre celle qui contient TOUTES les
pr√©cieuses informations; la premi√®re seulement le rang des nouvelles alors que
la deuxi√®me est tout simplement vide...

### Raffinons la strat√©gie de s√©lection

En inspectant davantage, on se rend compte qu'en s√©lectionnant certaines
classes CSS, on peut s√©lectionner tous les titres en m√™me temps, et ce, pour
tous les contenus. Investiguons cette piste:

```{r}
html_elements(x = items,
                         css = ".title") %>% html_text()

```

On se rend vite compte qu'en utilisant seulement la classe `.title`, il y a
d'autres √©l√©ments qui sont s√©lectionn√©s. Il faut donc raffiner davantage. Si
vous √™tes moins √† l'aise avec le HTML et le CSS, veuillez utiliser
SelectorGadget pour vous aider:

```{r}
html_elements(x = items,
              css = ".titleline > a") %>% html_text()
```

Voil√† qui semble faire exactement ce que nous voulons r√©colter.

Maintenant que nous savons ce que √ßa prend pour r√©colter une partie de
l'information, nous pouvons faire de m√™me pour toutes les diff√©rentes
informations et les assigner dans un tibble.

Nous pourrions extraire plus d'information que le texte mais pour le moment,
c'est seulement le texte qui nous int√©resse.

::: callout-important
## √Ä vous de jouer!

Tous les endroits avec des `""` vides devraient √™tre remplis!

‚è≤Ô∏è 15 minutes devraient suffire.
:::

```{r, eval=FALSE}

rank <- html_elements(x = items,
              css = "") %>% html_text()

title <- html_elements(x = items,
              css = ".titleline > a") %>% html_text()

score <- html_elements(x = items,
              css = "") %>% html_text()

author <- html_elements(x = items,
              css = "") %>% html_text()

time <- html_elements(x = items,
              css = "") %>% html_text()

comments <- html_elements(x = items,
              css = ".subline a+ a") %>% html_text()

# Bonus: pour obtenir l'URL la fonctionne html_attr() permet d'y arriver!
link <- html_elements(x = items,
              css = "") %>% html_attr("")

dat <- tibble::tibble(rank,
               title,
               score,
               author,
               time,
               comments,
               link
               )
dat
```

### Optimisation du script

Le code que nous venons d'utiliser a √©t√© pr√©par√© pour l'apprentissage. Dans la
vie r√©el, nous aurions probablement fait une fonction et extrait l'information
d'un seul coup.

Vous pourrez tenter le coup dans vos temps libres ü§†.

### Exercice libre

::: callout-note
Maintenant que nous avons exp√©riment√©, trouvons un site ensemble et essayons
d'extraire des donn√©es!
:::

```{r}

```

## Exporter ses donn√©es

Il est tout aussi important de bien exporter ses donn√©es. Par chance, la
majorit√© des packages d'importation offre au moins une fonction d'exportation
et plusieurs options int√©ressantes.

```{r, eval = FALSE}
write_csv(
  x,
  file,
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  num_threads = readr_threads(),
  progress = show_progress(),
  path = deprecated(),
  quote_escape = deprecated()
)
```
